{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c1a968-9abe-4ae8-91b2-f3ccf93b96a0",
   "metadata": {},
   "source": [
    "Линейная регрессия.\r\n",
    "Вам даны два вектора признаков и вектор целевой переменной. Постройте модель линейной регрессии и выведите на экран вектор весов модели для факторо в x  \n",
    "  и22 \r\n",
    " в формате массива numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e522a3b0-53bc-44b1-9bf1-a204a8a53a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x1 = np.array([1, 2, 3, 4, 5])\n",
    "x2 = np.array([6, 7, 8, 9, 10])\n",
    "y = np.array([11, 12, 13, 14, 15])\n",
    "reg = LinearRegression()\n",
    "\n",
    "arr = np.column_stack((x1, x2))\n",
    "reg.fit(arr, y)\n",
    "reg.coef_ = np.array([round(reg.coef_[0], 16), round(reg.coef_[1], 16)])\n",
    "\n",
    "# w = reg.coef_\n",
    "# print(w)\n",
    "print(reg.coef_[0] == 0.5)\n",
    "print(reg.coef_[1] == 0.5000000000000001)\n",
    "print(reg.coef_[0])\n",
    "print(reg.coef_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7296a2e-b992-4832-baa7-40fe95538fc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float128'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Задание данных с использованием np.float64 для большей точности\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m x1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat128)\n\u001b[0;32m      6\u001b[0m x2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m10\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat128)\n\u001b[0;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m15\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat128)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\__init__.py:347\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    348\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float128'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Задание данных с использованием np.float64 для большей точности\n",
    "x1 = np.array([1, 2, 3, 4, 5], dtype=np.float64)\n",
    "x2 = np.array([6, 7, 8, 9, 10], dtype=np.float64)\n",
    "y = np.array([11, 12, 13, 14, 15], dtype=np.float64)\n",
    "\n",
    "# Создание модели\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Формирование матрицы признаков\n",
    "arr = np.column_stack((x1, x2))\n",
    "\n",
    "# Обучаем модель\n",
    "reg.fit(arr, y)\n",
    "\n",
    "\n",
    "\n",
    "# Выводим сами коэффициенты\n",
    "print(reg.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d50b8-6626-4730-ac47-a852bb9c53c8",
   "metadata": {},
   "source": [
    "Вам даны два вектора признаков и вектор целевой переменной. Постройте модель линейной регрессии и выведите на экран предсказанное значение y если x1=5\r\n",
    ", а x2=6\r\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fdf0cef-7165-41a6-8b31-0658837cdb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "x1 = np.array([1, 2, 3, 4, 5])\n",
    "x2 = np.array([6, 7, 8, 9, 10])\n",
    "y = np.array([11, 12, 13, 14, 15])\n",
    "reg = LinearRegression()\n",
    "\n",
    "arr = np.column_stack((x1, x2))\n",
    "reg.fit(arr, y)\n",
    "ans = reg.predict([[5, 6]])[0]\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5382166-8d2f-4a1a-a3c6-da8cfb60394b",
   "metadata": {},
   "source": [
    "Напишите функцию calculate_metrics(y_true, y_pred), которая принимает на вход два списка y_true и y_pred, содержащих настоящие и предсказанные значения бинарных классов (0 или 1 соответственно). Функция должна возвращать словарь, содержащий значения метрик качества: accuracy, precision, recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c49d7d1-9b17-4a75-9fd3-da03f56d06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    tp = fp = fn = tn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            tp += 1  \n",
    "        elif yt == 0 and yp == 1:\n",
    "            fp += 1\n",
    "        elif yt == 1 and yp == 0:\n",
    "            fn += 1 \n",
    "        elif yt == 0 and yp == 0:\n",
    "            tn += 1\n",
    "    metrics = dict()\n",
    "    \n",
    "    metrics[\"accuracy\"] = ((tp + tn) / (tp + tn + fp + fn))\n",
    "    metrics[\"precision\"] = (tp / (tp + fn))\n",
    "    metrics[\"recall\"] =  (tp / (tp + fp))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5bbe8-3b33-4a4e-b47c-349e543fdf7c",
   "metadata": {},
   "source": [
    "Вам предложены искусственные данные, где зависимая переменная является бинарной. Постройте модель логистической регрессии на 80% выборки. Выведите на экран округленное до второго знака после запятой значение f1 score на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc8bdd4c-66ec-47cf-a091-eb0b6be56b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5263157894736842\n",
      "0.53\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = np.random.rand(100, 5)\n",
    "y = np.random.randint(0, 2, size=100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(random_state=42, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(round(f1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49735ef3-07ae-4d0f-a238-a33561020f4a",
   "metadata": {},
   "source": [
    "Обучите классификатор на основе решающего дерева для предсказания видов ирисов на основе измерений их лепестков и чашелистников. Установите гиперпараметры max_depth=3 и min_samples_split=5. Выведите значение accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55e412ed-7999-458d-b638-1524f794dda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=41) \n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, min_samples_split=5, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0458aff9-f715-46da-b6db-000499c94ac2",
   "metadata": {},
   "source": [
    "Напишите программу на Python для обучения модели случайного леса и градиентного бустинга на датасете iris. \r\n",
    "\r\n",
    "Используйте библиотеки sklearn и numpy для работы с данными. \r\n",
    "Разделите данные на обучающую и тестовую выборки в соотношении 70/30. \r\n",
    "Посчитайте accuracy для каждой модели на тестовой выборке и сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6f49a72-282d-4ae7-9e48-04665c1c19c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy случайного леса: 1.0\n",
      "Accuracy градиентного бустинга: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42) \n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_y_pred)\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100,\n",
    "learning_rate=0.1, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "gb_y_pred = gb.predict(X_test)\n",
    "gb_acc = accuracy_score(y_test, gb_y_pred)\n",
    "\n",
    "print(\"Accuracy случайного леса:\", round(rf_acc, 2))\n",
    "print(\"Accuracy градиентного бустинга:\", round(gb_acc, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
